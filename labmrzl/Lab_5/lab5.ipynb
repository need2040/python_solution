{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "594559d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import pytorch_lightning as pl \n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import  IterableDataset, DataLoader\n",
    "import random\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorboard\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3f9ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"d:/lab5dataset/Images/train/Angry/0.jpg\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baf63a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img/255).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dff0ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8dc7ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x297cd678440>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b15e8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = sorted(\n",
    "            [ d.name for d in os.scandir(\"D:/lab5dataset/Images/train\") if d.is_dir()]\n",
    "        )\n",
    "\n",
    "class_info = dict(enumerate(class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a627a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Angry',\n",
       " 1: 'Disgust',\n",
       " 2: 'Fear',\n",
       " 3: 'Happy',\n",
       " 4: 'Neutral',\n",
       " 5: 'Sad',\n",
       " 6: 'Surprise'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "efb83503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(IterableDataset):\n",
    "    def __init__(self, root_dir, shuffle = True):\n",
    "        super(myDataset).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.classes = sorted(\n",
    "            [d.name for d in os.scandir(root_dir) if d.is_dir()]\n",
    "        )\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "\n",
    "    def _get_file_paths(self):\n",
    "        file_paths = []\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(self.root_dir, cls)\n",
    "            if not os.path.isdir(cls_dir):\n",
    "                continue\n",
    "            for file in os.listdir(cls_dir):\n",
    "                file_path = os.path.join(cls_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_paths.append((file_path, cls))\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(file_paths)\n",
    "\n",
    "        return file_paths\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def __iter__(self):\n",
    "        file_paths = self._get_file_paths()\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        \n",
    "        if worker_info is None:  \n",
    "            iter_start = 0\n",
    "            iter_end = len(file_paths)\n",
    "        else:  \n",
    "            \n",
    "            per_worker = int(math.ceil(len(file_paths) / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start = worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, len(file_paths))\n",
    "        \n",
    "        for img_path, cls in file_paths[iter_start:iter_end]:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = (img / 255).astype(np.float32)\n",
    "            label = self.class_to_idx[cls]\n",
    "            yield img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a1b3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = myDataset(\"D:/lab5dataset/Images/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94b2cb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.90588236, 0.85882354, 0.8509804 , ..., 0.54509807, 0.5529412 ,\n",
       "         0.53333336],\n",
       "        [0.85882354, 0.91764706, 0.9137255 , ..., 0.54901963, 0.4392157 ,\n",
       "         0.48235294],\n",
       "        [0.8117647 , 0.8980392 , 0.9098039 , ..., 0.6039216 , 0.4627451 ,\n",
       "         0.27058825],\n",
       "        ...,\n",
       "        [0.80784315, 0.7647059 , 0.7137255 , ..., 0.47843137, 0.50980395,\n",
       "         0.48235294],\n",
       "        [0.7607843 , 0.78039217, 0.7137255 , ..., 0.49019608, 0.46666667,\n",
       "         0.5254902 ],\n",
       "        [0.6745098 , 0.8039216 , 0.7411765 , ..., 0.4392157 , 0.41568628,\n",
       "         0.4627451 ]], dtype=float32),\n",
       " 0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2acde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cd6fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModule (pl.LightningDataModule):\n",
    "    def __init__(self, train_dir, val_dir, test_dir, batch_size = batch_size, num_workers = 8):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.val_dir = val_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = myDataset(\n",
    "            root_dir=self.train_dir,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        self.val_dataset = myDataset(\n",
    "            root_dir=self.val_dir,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        self.test_dataset = myDataset(\n",
    "            root_dir= self.test_dir,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            shuffle=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979867b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c378d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "(batch_size, 1, 48,48) -> по 32 ядрам - (batch_size, 32, 48,48)\n",
    "maxPool c ядром 2 -> (batch_size, 32, 24,24)\n",
    "\n",
    "дальше аналогично по 64 фичам\n",
    "\n",
    "и по 128 фичам\n",
    "\n",
    "итог - (batch_size, 128,6,6)\n",
    "\n",
    "дальше flatten\n",
    "\n",
    "классификация = кроссэнтрония\n",
    "\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e8ccad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(pl.LightningModule):\n",
    "    def __init__(self, num_classes=7, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                           \n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                           \n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                            \n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "        self.train_acc = Accuracy(task='multiclass', num_classes=7)\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_metrics = []\n",
    "        self.val_metrics = []\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.train_acc(logits, y)\n",
    "\n",
    "        self.train_losses.append(loss.item())\n",
    "        self.train_metrics.append(acc.item())\n",
    "\n",
    "        self.log_dict({\n",
    "            \"training/loss\": loss,\n",
    "            \"training/acc\": acc\n",
    "        })\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.val_acc(logits, y)\n",
    "\n",
    "        self.val_losses.append(loss.item())\n",
    "        self.val_metrics.append(acc.item())\n",
    "\n",
    "        self.log_dict({\n",
    "            \"val/loss\": loss,\n",
    "            \"val/acc\": acc\n",
    "        })\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        acc = self.test_acc(logits, y)\n",
    "        self.log(\"test/acc\", acc)\n",
    "        return logits, y\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = sum(self.train_losses) / len(self.train_losses)\n",
    "        avg_acc = sum(self.train_metrics) / len(self.train_metrics)\n",
    "\n",
    "\n",
    "        print(f\"Train epoch {self.current_epoch}. Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")\n",
    "        self.train_losses.clear()\n",
    "        self.train_metrics.clear()\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = sum(self.val_losses) / len(self.val_losses)\n",
    "        avg_acc = sum(self.val_metrics) / len(self.val_metrics)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Val epoch {self.current_epoch}. Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")\n",
    "        self.val_losses.clear()\n",
    "        self.val_metrics.clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3a07396",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ImageModule(\n",
    "    train_dir=\"D:/lab5dataset/Images/train\",\n",
    "    val_dir=\"D:/lab5dataset/Images/validation\",\n",
    "    test_dir=\"D:/lab5dataset/Images/test\",\n",
    "    batch_size=128,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f3f43eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba24fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tensorboardlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f04d1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=201,\n",
    "    logger=logger,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    log_every_n_steps=1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426aebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | conv_layers | Sequential         | 92.7 K | train\n",
      "1 | fc_layers   | Sequential         | 1.2 M  | train\n",
      "2 | val_acc     | MulticlassAccuracy | 0      | train\n",
      "3 | train_acc   | MulticlassAccuracy | 0      | train\n",
      "-----------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.098     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b651884eb23148eba9eeafc075e4e2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arseny\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 0. Avg Loss: 1.8947, Avg Acc: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arseny\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24c987326594e06aed410831f9f08e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176ad36fcaa84406918cf37d2f802a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 0. Avg Loss: 1.6536, Avg Acc: 0.3434\n",
      "Train epoch 0. Avg Loss: 1.7255, Avg Acc: 0.2996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4f2b20a6f149bdb23db5c5f662c7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 1. Avg Loss: 1.5491, Avg Acc: 0.4165\n",
      "Train epoch 1. Avg Loss: 1.4888, Avg Acc: 0.4243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ec416b518249c0ae3280f4711c5e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 2. Avg Loss: 1.5318, Avg Acc: 0.4420\n",
      "Train epoch 2. Avg Loss: 1.3563, Avg Acc: 0.4821\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc82636d156418e9fedf2c259f92672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 3. Avg Loss: 1.4979, Avg Acc: 0.4530\n",
      "Train epoch 3. Avg Loss: 1.2695, Avg Acc: 0.5158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42842b715534a05bbc6ac5de5449fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 4. Avg Loss: 1.5141, Avg Acc: 0.4705\n",
      "Train epoch 4. Avg Loss: 1.1947, Avg Acc: 0.5473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53729f72a38b4a089074ae6d89ee8b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 5. Avg Loss: 1.4614, Avg Acc: 0.4854\n",
      "Train epoch 5. Avg Loss: 1.1264, Avg Acc: 0.5738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132c12fd127a44eea2622179df721c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 6. Avg Loss: 1.4911, Avg Acc: 0.4914\n",
      "Train epoch 6. Avg Loss: 1.0647, Avg Acc: 0.5983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd3ff055c8c41998707cd328ab74273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 7. Avg Loss: 1.5524, Avg Acc: 0.4877\n",
      "Train epoch 7. Avg Loss: 0.9976, Avg Acc: 0.6252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfff1f23d4a4486a30c0f22f9819cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 8. Avg Loss: 1.4760, Avg Acc: 0.4998\n",
      "Train epoch 8. Avg Loss: 0.9426, Avg Acc: 0.6474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6a8b2d8ccd4f32b278264710259bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 9. Avg Loss: 1.5738, Avg Acc: 0.5045\n",
      "Train epoch 9. Avg Loss: 0.8774, Avg Acc: 0.6700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b552127d1374430e889b2a880a9c1195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 10. Avg Loss: 1.7108, Avg Acc: 0.5009\n",
      "Train epoch 10. Avg Loss: 0.8140, Avg Acc: 0.6950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c919606343487bafe85cde535ba53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 11. Avg Loss: 1.7410, Avg Acc: 0.4968\n",
      "Train epoch 11. Avg Loss: 0.7534, Avg Acc: 0.7207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1a7173428b43bdbfc0a7f7d3cad327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 12. Avg Loss: 1.8645, Avg Acc: 0.5102\n",
      "Train epoch 12. Avg Loss: 0.6951, Avg Acc: 0.7399\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[172], line 12\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(model, datamodule)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m---> 12\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         preds\u001b[38;5;241m.\u001b[39mextend(logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     14\u001b[0m         targets\u001b[38;5;241m.\u001b[39mextend(y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[166], line 40\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[0;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(model, datamodule):\n",
    "    preds, targets = [], []\n",
    "\n",
    "    trainer = pl.Trainer(accelerator='gpu' if torch.cuda.is_available() else 'cpu')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            logits = model(x.cuda() if torch.cuda.is_available() else x)\n",
    "            preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "            targets.extend(y.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(model.hparams.num_classes))\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9696de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
