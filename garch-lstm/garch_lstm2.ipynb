{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download('^GSPC', start=\"2015-01-01\", end=\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_returns'] = np.log(data['^GSPC']/data['^GSPC'].shift(-1)) #non-squared \n",
    "data['volatility'] = data['log_returns'].rolling(window=5).apply(lambda x: (np.sqrt(np.sum(x**2)))) #non-sduared volatility\n",
    "data['volatility'] = data['volatility']*100\n",
    "data['log_returns'] = data['log_returns']*100\n",
    "data.drop(['^GSPC','index'], axis=1, inplace=True)\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(data) * 0.8)\n",
    "val_len = int(len(data)*0.1 + train_len)\n",
    "test_len = int(len(data)-train_len-val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:train_len]\n",
    "val_data = data.iloc[train_len:val_len]\n",
    "test_data = data.iloc[val_len:int(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>log_returns</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.844721</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.893325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.156274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.773017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843932</td>\n",
       "      <td>3.064932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1.455714</td>\n",
       "      <td>2.526099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-0.585095</td>\n",
       "      <td>2.338602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.405784</td>\n",
       "      <td>2.194310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.209347</td>\n",
       "      <td>2.503352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-1.731063</td>\n",
       "      <td>2.661804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker  log_returns  volatility\n",
       "0          1.844721    0.000000\n",
       "1          0.893325    0.000000\n",
       "2         -1.156274    0.000000\n",
       "3         -1.773017    0.000000\n",
       "4          0.843932    3.064932\n",
       "...             ...         ...\n",
       "2007       1.455714    2.526099\n",
       "2008      -0.585095    2.338602\n",
       "2009       0.405784    2.194310\n",
       "2010       1.209347    2.503352\n",
       "2011      -1.731063    2.661804\n",
       "\n",
       "[2012 rows x 2 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 11170.316193628138\n",
      "Iteration:      2,   Func. Count:     15,   Neg. LLF: 4643.98763551963\n",
      "Iteration:      3,   Func. Count:     22,   Neg. LLF: 5106.335316298678\n",
      "Iteration:      4,   Func. Count:     28,   Neg. LLF: 2635.042239531366\n",
      "Iteration:      5,   Func. Count:     32,   Neg. LLF: 2635.042094583123\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: 2635.0420945838796\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 2635.042094583123\n",
      "            Iterations: 6\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 6\n"
     ]
    }
   ],
   "source": [
    "garch = arch_model(train_data['log_returns'], vol='GARCH', p=1,q=1, mean='Zero')\n",
    "garch_fit = garch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Zero Mean - GARCH Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>log_returns</td>    <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mean Model:</th>         <td>Zero Mean</td>     <th>  Adj. R-squared:    </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vol Model:</th>            <td>GARCH</td>       <th>  Log-Likelihood:    </th> <td>  -2635.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Distribution:</th>        <td>Normal</td>       <th>  AIC:               </th> <td>   5276.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>        <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   5292.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                        <td></td>          <th>  No. Observations:  </th>    <td>2012</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Tue, Mar 18 2025</td>  <th>  Df Residuals:      </th>    <td>2012</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>14:46:43</td>      <th>  Df Model:          </th>      <td>0</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Volatility Model</caption>\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>        <th>P>|t|</th>     <th>95.0% Conf. Int.</th>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>omega</th>    <td>    0.0385</td> <td>1.101e-02</td> <td>    3.497</td>  <td>4.697e-04</td> <td>[1.693e-02,6.010e-02]</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alpha[1]</th> <td>    0.1960</td> <td>3.265e-02</td> <td>    6.001</td>  <td>1.957e-09</td>   <td>[  0.132,  0.260]</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beta[1]</th>  <td>    0.7795</td> <td>3.050e-02</td> <td>   25.556</td> <td>4.740e-144</td>   <td>[  0.720,  0.839]</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Covariance estimator: robust"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:} &    log\\_returns    & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Mean Model:}    &     Zero Mean      & \\textbf{  Adj. R-squared:    } &     0.000   \\\\\n",
       "\\textbf{Vol Model:}     &       GARCH        & \\textbf{  Log-Likelihood:    } &   -2635.04  \\\\\n",
       "\\textbf{Distribution:}  &       Normal       & \\textbf{  AIC:               } &    5276.08  \\\\\n",
       "\\textbf{Method:}        & Maximum Likelihood & \\textbf{  BIC:               } &    5292.90  \\\\\n",
       "\\textbf{}               &                    & \\textbf{  No. Observations:  } &    2012     \\\\\n",
       "\\textbf{Date:}          &  Tue, Mar 18 2025  & \\textbf{  Df Residuals:      } &    2012     \\\\\n",
       "\\textbf{Time:}          &      14:46:43      & \\textbf{  Df Model:          } &     0       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{95.0\\% Conf. Int.}  \\\\\n",
       "\\midrule\n",
       "\\textbf{omega}    &       0.0385  &    1.101e-02     &     3.497  &      4.697e-04       &   [1.693e-02,6.010e-02]     \\\\\n",
       "\\textbf{alpha[1]} &       0.1960  &    3.265e-02     &     6.001  &      1.957e-09       &     [  0.132,  0.260]       \\\\\n",
       "\\textbf{beta[1]}  &       0.7795  &    3.050e-02     &    25.556  &      4.740e-144      &     [  0.720,  0.839]       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Zero Mean - GARCH Model Results}\n",
       "\\end{center}\n",
       "\n",
       "Covariance estimator: robust"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                       Zero Mean - GARCH Model Results                        \n",
       "==============================================================================\n",
       "Dep. Variable:            log_returns   R-squared:                       0.000\n",
       "Mean Model:                 Zero Mean   Adj. R-squared:                  0.000\n",
       "Vol Model:                      GARCH   Log-Likelihood:               -2635.04\n",
       "Distribution:                  Normal   AIC:                           5276.08\n",
       "Method:            Maximum Likelihood   BIC:                           5292.90\n",
       "                                        No. Observations:                 2012\n",
       "Date:                Tue, Mar 18 2025   Df Residuals:                     2012\n",
       "Time:                        14:46:43   Df Model:                            0\n",
       "                              Volatility Model                              \n",
       "============================================================================\n",
       "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
       "----------------------------------------------------------------------------\n",
       "omega          0.0385  1.101e-02      3.497  4.697e-04 [1.693e-02,6.010e-02]\n",
       "alpha[1]       0.1960  3.265e-02      6.001  1.957e-09     [  0.132,  0.260]\n",
       "beta[1]        0.7795  3.050e-02     25.556 4.740e-144     [  0.720,  0.839]\n",
       "============================================================================\n",
       "\n",
       "Covariance estimator: robust\n",
       "\"\"\""
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garch_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inputs: tensor([[1.0000e+00, 5.6845e+00, 1.0019e+00],\n",
      "        [1.0000e+00, 4.0256e-01, 1.9382e+00],\n",
      "        [1.0000e+00, 4.3501e+00, 1.5373e+00],\n",
      "        [1.0000e+00, 6.5547e+00, 2.0461e+00],\n",
      "        [1.0000e+00, 2.9791e-01, 2.8432e+00],\n",
      "        [1.0000e+00, 4.0859e+00, 2.1498e+00],\n",
      "        [1.0000e+00, 2.7027e-01, 2.4221e+00],\n",
      "        [1.0000e+00, 2.6619e+00, 1.8495e+00],\n",
      "        [1.0000e+00, 1.4847e+00, 1.9270e+00],\n",
      "        [1.0000e+00, 2.7053e+00, 1.7459e+00],\n",
      "        [1.0000e+00, 1.3921e+00, 1.8632e+00],\n",
      "        [1.0000e+00, 1.3537e+00, 1.6826e+00],\n",
      "        [1.0000e+00, 1.6531e+00, 1.5486e+00],\n",
      "        [1.0000e+00, 2.8131e+00, 1.5146e+00],\n",
      "        [1.0000e+00, 3.0418e-01, 1.7229e+00],\n",
      "        [1.0000e+00, 2.6775e-03, 1.3668e+00],\n",
      "        [1.0000e+00, 1.3727e-01, 1.0573e+00],\n",
      "        [1.0000e+00, 1.1068e+00, 8.6758e-01],\n",
      "        [1.0000e+00, 1.1627e-02, 9.2867e-01],\n",
      "        [1.0000e+00, 9.0321e-01, 7.5239e-01],\n",
      "        [1.0000e+00, 1.3719e+00, 8.0732e-01],\n",
      "        [1.0000e+00, 2.8196e-01, 9.3949e-01],\n",
      "        [1.0000e+00, 1.1777e-02, 8.1404e-01],\n",
      "        [1.0000e+00, 7.5980e-01, 6.7218e-01],\n",
      "        [1.0000e+00, 3.7029e-01, 7.2249e-01],\n",
      "        [1.0000e+00, 6.7159e-05, 6.7980e-01],\n",
      "        [1.0000e+00, 3.2041e+00, 5.7587e-01],\n",
      "        [1.0000e+00, 1.2191e-01, 1.1439e+00],\n",
      "        [1.0000e+00, 6.2945e-01, 9.2514e-01],\n",
      "        [1.0000e+00, 8.7708e+00, 8.7349e-01],\n",
      "        [1.0000e+00, 2.9515e+00, 2.4656e+00],\n",
      "        [1.0000e+00, 6.6795e-01, 2.4162e+00]])\n",
      "Batch Targets: tensor([1.9382, 1.5373, 2.0461, 2.8432, 2.1498, 2.4221, 1.8495, 1.9270, 1.7459,\n",
      "        1.8632, 1.6826, 1.5486, 1.5146, 1.7229, 1.3668, 1.0573, 0.8676, 0.9287,\n",
      "        0.7524, 0.8073, 0.9395, 0.8140, 0.6722, 0.7225, 0.6798, 0.5759, 1.1439,\n",
      "        0.9251, 0.8735, 2.4656, 2.4162, 1.9250])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_ground_garch(omega, alpha, beta, n=1000):\n",
    "    \"\"\"\n",
    "    Generates synthetic GARCH(1,1) data.\n",
    "    Returns residuals (ϵ_t) and volatility (σ_t²).\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    am = arch_model(None, mean='Zero', vol='GARCH', p=1, q=1)\n",
    "    params = np.array([omega, alpha, beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].shift(-1).to_numpy(), am_data['volatility'].shift(-1).to_numpy()\n",
    "\n",
    "class GARCHDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for GARCH(1,1) data.\n",
    "    Each sample consists of:\n",
    "    - Input: (1, ϵ²_{t-1}, σ²_{t-1})\n",
    "    - Target: σ²_t\n",
    "    \"\"\"\n",
    "    def __init__(self, residuals, volatility):\n",
    "        \"\"\"\n",
    "        residuals: Array of residuals (ϵ_t)\n",
    "        volatility: Array of volatility (σ_t²)\n",
    "        \"\"\"\n",
    "        self.residuals = residuals\n",
    "        self.volatility = volatility\n",
    "        valid_indices = ~np.isnan(residuals) & ~np.isnan(volatility)\n",
    "        residuals = residuals[valid_indices]\n",
    "        volatility = volatility[valid_indices]\n",
    "        # Create input vectors (1, ϵ²_{t-1}, σ²_{t-1})\n",
    "        self.inputs = np.column_stack([\n",
    "            np.ones_like(residuals),  # 1\n",
    "            np.square(np.roll(residuals, 1)),  # ϵ²_{t-1}\n",
    "            np.square(np.roll(volatility, 1))  # σ²_{t-1}\n",
    "        ])\n",
    "\n",
    "        # Remove the first sample (t=0) because it has no t-1\n",
    "        self.inputs = self.inputs[1:]\n",
    "        self.targets = np.square(volatility[1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - Input: (1, ϵ²_{t-1}, σ²_{t-1}) as a tensor\n",
    "        - Target: σ²_t as a tensor\n",
    "        \"\"\"\n",
    "        input_sample = torch.tensor(self.inputs[idx], dtype=torch.float32)\n",
    "        target_sample = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return input_sample, target_sample\n",
    "\n",
    "# Generate synthetic GARCH(1,1) data\n",
    "residuals, volatility = generate_ground_garch(omega=0.1, alpha=0.2, beta=0.7, n=1000)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = GARCHDataset(residuals, volatility)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Iterate through the DataLoader\n",
    "for batch_inputs, batch_targets in dataloader:\n",
    "    print(\"Batch Inputs:\", batch_inputs)\n",
    "    print(\"Batch Targets:\", batch_targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_gjrgarch(omega, alpha, lmbda, beta, n = 1000):\n",
    "    am = arch_model(None, mean='Zero', p =1, q = 1, o =1)\n",
    "    params = np.array([omega,alpha,lmbda,beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_figarch(omega, beta, phi ,d, n = 1000):\n",
    "    am = arch_model(None, mean='Zero', vol='FIGARCH')\n",
    "    params= np.array([omega, beta, phi, d])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_garch(0.5,0.2,0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_gjrgarch(0.1,0.2,0.3,0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_figarch(0.1,0.2,0.3,0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGARCH (torch.nn.Module): \n",
    "    def __init__(self,  input_size = 1, hidden_size =1):\n",
    "        super(RNNGARCH, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        sigma_t = self.linear(x)\n",
    "        return sigma_t.squeeze()\n",
    "    \n",
    "    \n",
    "    def get_garch_parameters(self) -> tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Returns the GARCH(1,1) parameters (ω, α, β) from the layer's weights.\n",
    "        \"\"\"\n",
    "        weights = self.linear.weight.data.squeeze().tolist()\n",
    "        omega, alpha, beta = weights\n",
    "        return omega, alpha, beta\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the dataset\n",
    "for batch_inputs, batch_targets in dataloader:\n",
    "    if torch.isnan(batch_targets).any():\n",
    "        print(\"NaNs found in inputs or targets!\")\n",
    "    if torch.isinf(batch_inputs).any() or torch.isinf(batch_targets).any():\n",
    "        print(\"Infs found in inputs or targets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GARCHNegativeLogLikelihood(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, residuals: torch.Tensor, estimated_volatility: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Ensure estimated_volatility is positive to avoid numerical issues\n",
    "        estimated_volatility = torch.clamp(estimated_volatility, min=1e-8)\n",
    "\n",
    "        # Compute the two terms of the negative log-likelihood\n",
    "        term1 = 0.5 * torch.log(estimated_volatility)  # log(σ_t²) / 2\n",
    "        term2 = (residuals ** 2) / (2 * estimated_volatility)  # ϵ_t² / (2 * σ_t²)\n",
    "\n",
    "        # Sum the terms and average over the batch\n",
    "        loss = torch.mean((term1 + term2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Average Loss: 1.6128880634062063e-14\n",
      "Epoch 200, Average Loss: 2.6999004876580954e-13\n",
      "Epoch 300, Average Loss: 3.335943153659482e-11\n",
      "Epoch 400, Average Loss: 6.402443415254311e-05\n",
      "Epoch 500, Average Loss: 0.00013874447361672537\n",
      "Epoch 600, Average Loss: 6.210604173041007e-08\n",
      "Epoch 700, Average Loss: 2.12940318572441e-08\n",
      "Epoch 800, Average Loss: 4.796076114033099e-06\n",
      "Epoch 900, Average Loss: 4.806647355692917e-05\n",
      "Epoch 1000, Average Loss: 1.1889066849068985e-08\n",
      "Trained GARCH(1,1) Parameters: ω=0.09993383288383484, α=0.20000706613063812, β=0.7001566886901855\n"
     ]
    }
   ],
   "source": [
    "# Create the GARCH(1,1) RNN layer\n",
    "garch_layer = RNNGARCH()\n",
    "\n",
    "# Create the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.Adam(garch_layer.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        # Forward pass\n",
    "        estimated_volatility = garch_layer(batch_inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        residuals = batch_targets  # Assuming batch_targets are σ²_t, residuals are ϵ_t = sqrt(σ²_t)\n",
    "        loss = loss_fn(residuals, estimated_volatility)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Average Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "# Get the trained GARCH(1,1) parameters\n",
    "omega, alpha, beta = garch_layer.get_garch_parameters()\n",
    "print(f\"Trained GARCH(1,1) Parameters: ω={omega}, α={alpha}, β={beta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
