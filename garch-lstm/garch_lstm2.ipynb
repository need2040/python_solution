{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download('^GSPC', start=\"2015-01-01\", end=\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_returns'] = np.log(data['^GSPC']/data['^GSPC'].shift(-1)) #non-squared \n",
    "data['volatility'] = data['log_returns'].rolling(window=5).apply(lambda x: (np.sqrt(np.sum(x**2)))) #non-sduared volatility\n",
    "data['volatility'] = data['volatility']*100\n",
    "data['log_returns'] = data['log_returns']*100\n",
    "data.drop(['^GSPC','index'], axis=1, inplace=True)\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(data) * 0.8)\n",
    "val_len = int(len(data)*0.1 + train_len)\n",
    "test_len = int(len(data)-train_len-val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:train_len]\n",
    "val_data = data.iloc[train_len:val_len]\n",
    "test_data = data.iloc[val_len:int(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>log_returns</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.844721</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.893325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.156274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.773017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843932</td>\n",
       "      <td>3.064932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1.455714</td>\n",
       "      <td>2.526099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-0.585095</td>\n",
       "      <td>2.338602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.405784</td>\n",
       "      <td>2.194310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.209347</td>\n",
       "      <td>2.503352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-1.731063</td>\n",
       "      <td>2.661804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2012 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker  log_returns  volatility\n",
       "0          1.844721    0.000000\n",
       "1          0.893325    0.000000\n",
       "2         -1.156274    0.000000\n",
       "3         -1.773017    0.000000\n",
       "4          0.843932    3.064932\n",
       "...             ...         ...\n",
       "2007       1.455714    2.526099\n",
       "2008      -0.585095    2.338602\n",
       "2009       0.405784    2.194310\n",
       "2010       1.209347    2.503352\n",
       "2011      -1.731063    2.661804\n",
       "\n",
       "[2012 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 11170.316193628138\n",
      "Iteration:      2,   Func. Count:     15,   Neg. LLF: 4643.98763551963\n",
      "Iteration:      3,   Func. Count:     22,   Neg. LLF: 5106.335316298678\n",
      "Iteration:      4,   Func. Count:     28,   Neg. LLF: 2635.042239531366\n",
      "Iteration:      5,   Func. Count:     32,   Neg. LLF: 2635.042094583123\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: 2635.0420945838796\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 2635.042094583123\n",
      "            Iterations: 6\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 6\n"
     ]
    }
   ],
   "source": [
    "garch = arch_model(train_data['log_returns'], vol='GARCH', p=1,q=1, mean='Zero')\n",
    "garch_fit = garch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Zero Mean - GARCH Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>log_returns</td>    <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mean Model:</th>         <td>Zero Mean</td>     <th>  Adj. R-squared:    </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vol Model:</th>            <td>GARCH</td>       <th>  Log-Likelihood:    </th> <td>  -2635.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Distribution:</th>        <td>Normal</td>       <th>  AIC:               </th> <td>   5276.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>        <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   5292.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                        <td></td>          <th>  No. Observations:  </th>    <td>2012</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Wed, Mar 19 2025</td>  <th>  Df Residuals:      </th>    <td>2012</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>00:43:18</td>      <th>  Df Model:          </th>      <td>0</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Volatility Model</caption>\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>        <th>P>|t|</th>     <th>95.0% Conf. Int.</th>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>omega</th>    <td>    0.0385</td> <td>1.101e-02</td> <td>    3.497</td>  <td>4.697e-04</td> <td>[1.693e-02,6.010e-02]</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alpha[1]</th> <td>    0.1960</td> <td>3.265e-02</td> <td>    6.001</td>  <td>1.957e-09</td>   <td>[  0.132,  0.260]</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beta[1]</th>  <td>    0.7795</td> <td>3.050e-02</td> <td>   25.556</td> <td>4.740e-144</td>   <td>[  0.720,  0.839]</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Covariance estimator: robust"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:} &    log\\_returns    & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Mean Model:}    &     Zero Mean      & \\textbf{  Adj. R-squared:    } &     0.000   \\\\\n",
       "\\textbf{Vol Model:}     &       GARCH        & \\textbf{  Log-Likelihood:    } &   -2635.04  \\\\\n",
       "\\textbf{Distribution:}  &       Normal       & \\textbf{  AIC:               } &    5276.08  \\\\\n",
       "\\textbf{Method:}        & Maximum Likelihood & \\textbf{  BIC:               } &    5292.90  \\\\\n",
       "\\textbf{}               &                    & \\textbf{  No. Observations:  } &    2012     \\\\\n",
       "\\textbf{Date:}          &  Wed, Mar 19 2025  & \\textbf{  Df Residuals:      } &    2012     \\\\\n",
       "\\textbf{Time:}          &      00:43:18      & \\textbf{  Df Model:          } &     0       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{95.0\\% Conf. Int.}  \\\\\n",
       "\\midrule\n",
       "\\textbf{omega}    &       0.0385  &    1.101e-02     &     3.497  &      4.697e-04       &   [1.693e-02,6.010e-02]     \\\\\n",
       "\\textbf{alpha[1]} &       0.1960  &    3.265e-02     &     6.001  &      1.957e-09       &     [  0.132,  0.260]       \\\\\n",
       "\\textbf{beta[1]}  &       0.7795  &    3.050e-02     &    25.556  &      4.740e-144      &     [  0.720,  0.839]       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Zero Mean - GARCH Model Results}\n",
       "\\end{center}\n",
       "\n",
       "Covariance estimator: robust"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                       Zero Mean - GARCH Model Results                        \n",
       "==============================================================================\n",
       "Dep. Variable:            log_returns   R-squared:                       0.000\n",
       "Mean Model:                 Zero Mean   Adj. R-squared:                  0.000\n",
       "Vol Model:                      GARCH   Log-Likelihood:               -2635.04\n",
       "Distribution:                  Normal   AIC:                           5276.08\n",
       "Method:            Maximum Likelihood   BIC:                           5292.90\n",
       "                                        No. Observations:                 2012\n",
       "Date:                Wed, Mar 19 2025   Df Residuals:                     2012\n",
       "Time:                        00:43:18   Df Model:                            0\n",
       "                              Volatility Model                              \n",
       "============================================================================\n",
       "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
       "----------------------------------------------------------------------------\n",
       "omega          0.0385  1.101e-02      3.497  4.697e-04 [1.693e-02,6.010e-02]\n",
       "alpha[1]       0.1960  3.265e-02      6.001  1.957e-09     [  0.132,  0.260]\n",
       "beta[1]        0.7795  3.050e-02     25.556 4.740e-144     [  0.720,  0.839]\n",
       "============================================================================\n",
       "\n",
       "Covariance estimator: robust\n",
       "\"\"\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garch_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inputs: tensor([[1.0000e+00, 2.9918e-02, 8.3348e-01],\n",
      "        [1.0000e+00, 1.0848e+00, 1.3770e+00],\n",
      "        [1.0000e+00, 2.2855e+00, 1.2809e+00],\n",
      "        [1.0000e+00, 9.8939e-02, 1.4537e+00],\n",
      "        [1.0000e+00, 4.5515e-03, 1.1374e+00],\n",
      "        [1.0000e+00, 1.1093e-01, 8.9708e-01],\n",
      "        [1.0000e+00, 2.6595e-01, 7.5014e-01],\n",
      "        [1.0000e+00, 1.3815e+00, 6.7829e-01],\n",
      "        [1.0000e+00, 3.8093e-01, 8.5110e-01],\n",
      "        [1.0000e+00, 6.2615e-01, 7.7196e-01],\n",
      "        [1.0000e+00, 5.5434e-02, 7.6560e-01],\n",
      "        [1.0000e+00, 8.0816e-01, 6.4701e-01],\n",
      "        [1.0000e+00, 2.9182e+00, 7.1454e-01],\n",
      "        [1.0000e+00, 7.4784e-02, 1.1838e+00],\n",
      "        [1.0000e+00, 4.1292e-01, 9.4362e-01],\n",
      "        [1.0000e+00, 3.6793e-01, 8.4312e-01],\n",
      "        [1.0000e+00, 2.2497e-01, 7.6377e-01],\n",
      "        [1.0000e+00, 7.2304e-01, 6.7963e-01],\n",
      "        [1.0000e+00, 7.1127e-04, 7.2035e-01],\n",
      "        [1.0000e+00, 1.2706e-01, 6.0439e-01],\n",
      "        [1.0000e+00, 4.0423e+00, 5.4848e-01],\n",
      "        [1.0000e+00, 6.0033e-03, 1.2924e+00],\n",
      "        [1.0000e+00, 6.5438e-01, 1.0059e+00],\n",
      "        [1.0000e+00, 6.1362e+00, 9.3499e-01],\n",
      "        [1.0000e+00, 2.9322e-05, 1.9817e+00],\n",
      "        [1.0000e+00, 1.0322e-01, 1.4872e+00],\n",
      "        [1.0000e+00, 1.3523e-01, 1.1617e+00],\n",
      "        [1.0000e+00, 1.0042e-02, 9.4023e-01],\n",
      "        [1.0000e+00, 1.0084e+00, 7.6017e-01],\n",
      "        [1.0000e+00, 8.3383e-02, 8.3379e-01],\n",
      "        [1.0000e+00, 3.9209e-01, 7.0033e-01],\n",
      "        [1.0000e+00, 1.5827e-01, 6.6865e-01]])\n",
      "Batch Targets: tensor([1.3770, 1.2809, 1.4537, 1.1374, 0.8971, 0.7501, 0.6783, 0.8511, 0.7720,\n",
      "        0.7656, 0.6470, 0.7145, 1.1838, 0.9436, 0.8431, 0.7638, 0.6796, 0.7204,\n",
      "        0.6044, 0.5485, 1.2924, 1.0059, 0.9350, 1.9817, 1.4872, 1.1617, 0.9402,\n",
      "        0.7602, 0.8338, 0.7003, 0.6687, 0.5997])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_ground_garch(omega, alpha, beta, n=1000):\n",
    "    \"\"\"\n",
    "    Generates synthetic GARCH(1,1) data.\n",
    "    Returns residuals (Ïµ_t) and volatility (Ïƒ_tÂ²).\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    am = arch_model(None, mean='Zero', vol='GARCH', p=1, q=1)\n",
    "    params = np.array([omega, alpha, beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()\n",
    "\n",
    "class GARCH11Dataset(Dataset):\n",
    "    def __init__(self, residuals, volatility):\n",
    "        self.residuals = residuals\n",
    "        self.volatiliy = volatility\n",
    "\n",
    "        self.input = np.column_stack([\n",
    "            np.ones_like(residuals),\n",
    "            np.square(np.roll(residuals,1)),\n",
    "            np.square(np.roll(volatility,1))\n",
    "        ])\n",
    "        self.output = np.square(np.roll(volatility,0))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_sample = torch.tensor(self.input[index], dtype=torch.float32)\n",
    "        output_sample = torch.tensor(self.output[index], dtype=torch.float32)\n",
    "        return input_sample, output_sample\n",
    "    \n",
    "# Generate synthetic GARCH(1,1) data\n",
    "residuals, volatility = generate_ground_garch(omega=0.1, alpha=0.2, beta=0.7, n=1000)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = GARCH11Dataset(residuals, volatility)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Iterate through the DataLoader\n",
    "for batch_inputs, batch_targets in dataloader:\n",
    "    print(\"Batch Inputs:\", batch_inputs)\n",
    "    print(\"Batch Targets:\", batch_targets)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_gjrgarch(omega, alpha, lmbda, beta, n = 1000):\n",
    "    am = arch_model(None, mean='Zero', p =1, q = 1, o =1)\n",
    "    params = np.array([omega,alpha,lmbda,beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_figarch(omega, beta, phi ,d, n = 1000):\n",
    "    am = arch_model(None, mean='Zero', vol='FIGARCH')\n",
    "    params= np.array([omega, beta, phi, d])\n",
    "    am_data = am.simulate(params, n)\n",
    "\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_garch(0.5,0.2,0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_gjrgarch(0.1,0.2,0.3,0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_figarch(0.1,0.2,0.3,0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGARCH (torch.nn.Module): \n",
    "    def __init__(self,  input_size=3, hidden_size=1):\n",
    "        super(RNNGARCH, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(3, 1, bias=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        sigma_t = self.linear(x)\n",
    "        return sigma_t.squeeze()\n",
    "    \n",
    "    \n",
    "    def get_garch_parameters(self) -> tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Returns the GARCH(1,1) parameters (Ï‰, Î±, Î²) from the layer's weights.\n",
    "        \"\"\"\n",
    "        weights = self.linear.weight.data.squeeze().tolist()\n",
    "        omega, alpha, beta = weights\n",
    "        return omega, alpha, beta\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GARCHNegativeLogLikelihood(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, residuals: torch.Tensor, estimated_volatility: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Ensure estimated_volatility is positive to avoid numerical issues\n",
    "        \n",
    "\n",
    "        # Compute the two terms of the negative log-likelihood\n",
    "        term1 = 0.5 * torch.log(estimated_volatility)  # log(Ïƒ_tÂ²) / 2\n",
    "        term2 = (residuals ** 2) / (2 * estimated_volatility)  # Ïµ_tÂ² / (2 * Ïƒ_tÂ²)\n",
    "\n",
    "        # Sum the terms and average over the batch\n",
    "        loss = torch.mean((term1 + term2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Average Loss: 0.18196030044055078\n",
      "Epoch 200, Average Loss: 0.01849713049159618\n",
      "Epoch 300, Average Loss: 0.008853432183968835\n",
      "Epoch 400, Average Loss: 0.00331975589870126\n",
      "Epoch 500, Average Loss: 0.0008417066076162882\n",
      "Epoch 600, Average Loss: 0.00046252701681481767\n",
      "Epoch 700, Average Loss: 0.0004614262414905923\n",
      "Epoch 800, Average Loss: 0.00046155216714893754\n",
      "Epoch 900, Average Loss: 0.00046154858785119046\n",
      "Epoch 1000, Average Loss: 0.0004615058415113893\n",
      "Trained GARCH(1,1) Parameters: Ï‰=0.10086606442928314, Î±=0.19965048134326935, Î²=0.6997845768928528\n"
     ]
    }
   ],
   "source": [
    "# Create the GARCH(1,1) RNN layer\n",
    "garch_layer = RNNGARCH()\n",
    "\n",
    "# Create the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.Adam(garch_layer.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        # Forward pass\n",
    "        estimated_volatility = garch_layer(batch_inputs)\n",
    "        residuals = torch.sqrt(batch_inputs[:,-1])\n",
    "        # Compute loss\n",
    "        residuals = batch_targets  # Assuming batch_targets are ÏƒÂ²_t, residuals are Ïµ_t = sqrt(ÏƒÂ²_t)\n",
    "        loss = loss_fn(residuals, estimated_volatility)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Average Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "# Get the trained GARCH(1,1) parameters\n",
    "omega, alpha, beta = garch_layer.get_garch_parameters()\n",
    "print(f\"Trained GARCH(1,1) Parameters: Ï‰={omega}, Î±={alpha}, Î²={beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERICAL UNDERVALUES "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
