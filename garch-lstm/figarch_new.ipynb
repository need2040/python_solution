{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FIGARCH_CNN(nn.Module):\n",
    "    def __init__(self, truncation_size, init_beta=0.5, init_phi=0.5, init_d=0.5, init_omega = 0.3):\n",
    "        super(FIGARCH_CNN, self).__init__()\n",
    "        self.truncation_size = truncation_size\n",
    "        # Параметры FI-GARCH (обучаемые)\n",
    "        self.beta = nn.Parameter(torch.tensor(init_beta))\n",
    "        self.phi = nn.Parameter(torch.tensor(init_phi))\n",
    "        self.d = nn.Parameter(torch.tensor(init_d))\n",
    "        self.omega = nn.Parameter(torch.tensor(init_omega))\n",
    "        # Инициализация весов свёртки (lambda_k)\n",
    "        self.register_buffer('lambdas', torch.zeros(truncation_size))\n",
    "        self.update_lambdas()  # Первоначальный расчёт lambda_k\n",
    "\n",
    "    def update_lambdas(self):\n",
    "        \"\"\"Обновляет веса lambda_k на основе текущих beta, phi, d.\"\"\"\n",
    "        deltas = torch.ones(self.truncation_size)\n",
    "        lambdas = torch.zeros(self.truncation_size)\n",
    "        \n",
    "        # Рекуррентный расчёт lambda_k\n",
    "        lambdas[0] = 1.0  # lambda_0\n",
    "        if self.truncation_size > 1:\n",
    "            lambdas[1] = self.phi - self.beta + self.d\n",
    "            deltas[1] = (1 - self.d) / 1\n",
    "        \n",
    "        for k in range(2, self.truncation_size):\n",
    "            deltas[k] = deltas[k-1] * (k - 1 - self.d) / k\n",
    "            lambdas[k] = self.beta * lambdas[k-1] + ((k - 1 - self.d)/k - self.phi) * deltas[k-1]\n",
    "        \n",
    "        self.lambdas = lambdas.detach()  # Отключаем градиенты для lambda_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: тензор размером (batch_size, seq_len), где seq_len >= truncation_size.\"\"\"\n",
    "        # Применяем свёртку с весами lambda_k\n",
    "        x = x.unfold(dimension=1, size=self.truncation_size, step=1)\n",
    "        sigma_sq = torch.sum(x * self.lambdas.flip(0), dim=2)  # Скалярное произведение\n",
    "        return sigma_sq\n",
    "\n",
    "# Пример использования:\n",
    "truncation_size = 10\n",
    "model = FIGARCH_CNN(truncation_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Пример данных: (batch_size, seq_len)\n",
    "epsilon_sq = torch.rand(32, 100)  # 32 батча, 100 временных точек\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.update_lambdas()  # Обновляем lambda_k перед каждым forward\n",
    "    sigma_sq_pred = model(epsilon_sq)\n",
    "    loss = torch.mean((sigma_sq_pred - true_sigma_sq)**2)  # Пример MSE\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
