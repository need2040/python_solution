{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2bd0d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from arch import arch_model\n",
    "from pytorch_lightning.loggers import  TensorBoardLogger\n",
    "from scipy.optimize import root\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "586485eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Генерация данных\n",
    "def generate_ground_garch(omega, d, phi, beta, n=3000):\n",
    "    am = arch_model(None, mean='Zero', vol='FIGARCH', p=1, q=1, power=2)\n",
    "    params = np.array([omega, d, phi, beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f86e8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset для полных последовательностей\n",
    "class FullSequenceDataset(Dataset):\n",
    "    def __init__(self, eps, vol, truncation_size, scale=100):\n",
    "        super().__init__()\n",
    "        self.eps_squared = torch.tensor(np.square(eps) * scale)\n",
    "        self.vol = (torch.tensor(vol * scale))\n",
    "        self.truncation_size = truncation_size\n",
    "        self.eps_squared = self.eps_squared.float()\n",
    "        self.vol = self.vol.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eps_squared) - self.truncation_size  # Количество возможных окон\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращаем окно остатков и соответствующий таргет\n",
    "        return (\n",
    "            self.eps_squared[idx:idx+self.truncation_size],\n",
    "            self.eps_squared[idx+self.truncation_size]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b0dd8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIGARCHDM(pl.LightningDataModule):\n",
    "    def __init__(self, eps, vol, truncation_size, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.vol = vol\n",
    "        self.truncation_size = truncation_size\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage = None):\n",
    "        self.train_dataset = FullSequenceDataset(self.eps, self.vol, self.truncation_size)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size= self.batch_size ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "92698769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectedNLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, pred_var, target_eps_squared):\n",
    "\n",
    "        loss =  (0.5*(torch.log(pred_var)) + (target_eps_squared/(2*pred_var))) \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d8074529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Модель FIGARCH с CNN\n",
    "class FullConvFIGARCH(pl.LightningModule):\n",
    "    def __init__(self, truncation_size, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.truncation_size = truncation_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.linspace(1.0, 0.1, truncation_size))\n",
    "        \n",
    "        self.loss_fn = CorrectedNLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = self.weights\n",
    "        #weights = torch.nn.functional.softplus(self.weights)\n",
    "        return torch.sum(x * weights, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        eps_window, target_eps = batch\n",
    "        pred_var = self.forward(eps_window)\n",
    "        loss = self.loss_fn(pred_var, target_eps)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=20, \n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            #'lr_scheduler': {\n",
    "            #    'scheduler': scheduler,\n",
    "            #     'monitor': 'train_loss'\n",
    "            #}\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5a67eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omega > 0 <- 1\n",
    "# 0 <= d <= 1 <- 2\n",
    "# 0 <= phi <= (1 - d) / 2 <- 2\n",
    "# 0 <= beta <= d + phi <- 2\n",
    "\n",
    "\n",
    "omega, d, phi, beta = 0.1, 0.5, 0.2, 0.3\n",
    "data, volat = generate_ground_garch(omega, d, phi, beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d76b075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [omega, d, phi, beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bc8fe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_size = 5\n",
    "batch_size = (len(data) - truncation_size)//1\n",
    "#batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b64683a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullConvFIGARCH(truncation_size)\n",
    "dm = FIGARCHDM(data, volat, truncation_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9aea5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('tb_logs', 'figarch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dc556056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=2000, accelerator='auto', logger= logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "40da4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Arseny\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name         | Type           | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss_fn      | CorrectedNLoss | 0      | train\n",
      "  | other params | n/a            | 5      | n/a  \n",
      "--------------------------------------------------------\n",
      "5         Trainable params\n",
      "0         Non-trainable params\n",
      "5         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Arseny\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Arseny\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc0be6bf09d419cbf71cdd9243cd0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2000` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e141a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights: tensor([0.7038, 0.3413, 0.2951, 0.1969, 0.1689])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    actual_lambdas =  model.weights.data.flip(0)\n",
    "    print(\"Learned weights:\", actual_lambdas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "091f56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompute_lambdas(lambdas):\n",
    "    from scipy.optimize import least_squares\n",
    "    \n",
    "    def equations(vars):\n",
    "        d, phi, beta = vars\n",
    "        eqs = [\n",
    "            phi - beta + d - lambdas[0],\n",
    "            (d - beta)*(beta - phi) + d*(1 - d)/2 - lambdas[1],\n",
    "            beta*(d*beta - d*phi - beta**2 + beta*phi + d*(1 - d)/2) + d*(1 - d)/2*((2 - d)/3 - phi) - lambdas[2]\n",
    "        ]\n",
    "        return eqs\n",
    "    \n",
    "    # Ограничения: 0 ≤ d ≤ 1, 0 ≤ phi ≤ (1-d)/2, 0 ≤ beta ≤ d + phi\n",
    "    bounds = ([0, 0, 0], [1, 1, 1])\n",
    "    \n",
    "    # Начальное приближение (можно попробовать несколько вариантов)\n",
    "    initial_guess = [0.5, 0.1, 0.3]\n",
    "    \n",
    "    sol = least_squares(equations, initial_guess)\n",
    "    \n",
    "    if not sol.success:\n",
    "        print(\"Warning: Solution not found!\", sol.message)\n",
    "    \n",
    "    return sol.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "36a04d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs =decompute_lambdas(actual_lambdas)\n",
    "\n",
    "#Думаю нужно разобраться с выходами модели - возможно несоответствие по индексам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "df840775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.41139252, -0.1403552 ,  0.63007106])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "67b54f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "80750c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1689, 0.1969, 0.2951, 0.3413, 0.7038])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2d1f2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_omega(weights, eps_squared, vol_series):\n",
    "    \"\"\"\n",
    "    weights: learned lambdas (λ)\n",
    "    eps_squared: εₜ² (квадраты остатков)\n",
    "    vol_series: σₜ² (волатильность в квадрате)\n",
    "    \"\"\"\n",
    "    weights = weights.numpy()\n",
    "    truncation_size = len(weights)\n",
    "    \n",
    "    # Предсказание без omega: Σλᵢεₜ₋ᵢ²\n",
    "    pred = np.sum(weights * eps_squared[:truncation_size])\n",
    "    \n",
    "    # omega = σₜ² - Σλᵢεₜ₋ᵢ²\n",
    "    omega = vol_series[truncation_size] - pred\n",
    "    \n",
    "    return max(omega, 1e-6)  # Омега должна быть строго положительной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1b34339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_omega = compute_omega(actual_lambdas, data, volat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a636b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.567960819868222"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3874a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_outputs, ground_truth, pred_omega, filename='figarch_results.json'):\n",
    "    # Подготовка данных\n",
    "    result = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'ground_truth': {\n",
    "            'omega' : float(omega),\n",
    "            'd': float(ground_truth[1]),\n",
    "            'phi': float(ground_truth[2]),\n",
    "            'beta': float(ground_truth[3]),\n",
    "        },\n",
    "        'model_params': {\n",
    "            'omega' : float(pred_omega),\n",
    "            'd': float(model_outputs[0]),\n",
    "            'phi': float(model_outputs[1]),\n",
    "            'beta': float(model_outputs[2])\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    # Запись в файл (дозапись)\n",
    "    mode = 'a' if os.path.exists(filename) else 'w'\n",
    "    with open(filename, mode, encoding='utf-8') as f:\n",
    "        f.write(json.dumps(result, indent=4) + '\\n')  # Добавляем перевод строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "46665b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(model_outputs, ground_truth, pred_omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595ceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
