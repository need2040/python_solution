{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd0d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from arch import arch_model\n",
    "from pytorch_lightning.loggers import  TensorBoardLogger\n",
    "from scipy.optimize import root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586485eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Генерация данных\n",
    "def generate_ground_garch(omega, d, phi, beta, n=3000):\n",
    "    am = arch_model(None, mean='Zero', vol='FIGARCH', p=1, q=1, power=2)\n",
    "    params = np.array([omega, d, phi, beta])\n",
    "    am_data = am.simulate(params, n)\n",
    "    return am_data['data'].to_numpy(), am_data['volatility'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86e8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset для полных последовательностей\n",
    "class FullSequenceDataset(Dataset):\n",
    "    def __init__(self, eps, vol, truncation_size, scale=100):\n",
    "        super().__init__()\n",
    "        self.eps_squared = torch.tensor(np.square(eps) * scale)\n",
    "        self.vol = (torch.tensor(vol)- 0.095) * scale\n",
    "        self.truncation_size = truncation_size\n",
    "        self.eps_squared = self.eps_squared.float()\n",
    "        self.vol = self.vol.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eps_squared) - self.truncation_size  # Количество возможных окон\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращаем окно остатков и соответствующий таргет\n",
    "        return (\n",
    "            self.eps_squared[idx:idx+self.truncation_size],\n",
    "            self.eps_squared[idx+self.truncation_size]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dd8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIGARCHDM(pl.LightningDataModule):\n",
    "    def __init__(self, eps, vol, truncation_size, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.vol = vol\n",
    "        self.truncation_size = truncation_size\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage = None):\n",
    "        self.train_dataset = FullSequenceDataset(self.eps, self.vol, self.truncation_size)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size= self.batch_size ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92698769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectedNLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, pred_var, target_eps_squared):\n",
    "\n",
    "        loss =  (0.5*(torch.log(pred_var)) + (target_eps_squared/(2*pred_var))) \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8074529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Модель FIGARCH с CNN\n",
    "class FullConvFIGARCH(pl.LightningModule):\n",
    "    def __init__(self, truncation_size, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.truncation_size = truncation_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.linspace(1.0, 0.1, truncation_size))\n",
    "        \n",
    "        self.loss_fn = CorrectedNLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return torch.sum(x * self.weights, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        eps_window, target_eps = batch\n",
    "        pred_var = self.forward(eps_window)\n",
    "        loss = self.loss_fn(pred_var, target_eps)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'train_loss'\n",
    "            }\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a67eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "omega, d, phi, beta = 0.1, 0.5, 0.2, 0.5\n",
    "data, volat = generate_ground_garch(omega, d, phi, beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8fe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_size = 10\n",
    "batch_size = len(data) - truncation_size\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64683a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullConvFIGARCH(truncation_size)\n",
    "dm = FIGARCHDM(data, volat, truncation_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aea5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('tb_logs', 'figarch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc556056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1200, accelerator='auto', logger= logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40da4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name         | Type           | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss_fn      | CorrectedNLoss | 0      | train\n",
      "  | other params | n/a            | 10     | n/a  \n",
      "--------------------------------------------------------\n",
      "10        Trainable params\n",
      "0         Non-trainable params\n",
      "10        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6167a539e804b55ab16a831462e542e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1200` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e141a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights: tensor([0.1965, 0.1042, 0.1110, 0.0868, 0.1048, 0.1119, 0.0760, 0.1181, 0.1075,\n",
      "        0.2992])\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned weights:\", model.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091f56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompute_lambdas(lambdas):\n",
    "    truncation_size = len(lambdas)\n",
    "    \n",
    "    def equations(vars):\n",
    "        d, phi, beta = vars\n",
    "        eq1 = phi - beta + d - lambdas[0]\n",
    "        eq2 = (d - beta) * (beta - phi) + d * (1 - d) / 2 - lambdas[1]\n",
    "\n",
    "        term1 = beta * (d * beta - d * phi - beta**2 + beta * phi + d * (1 - d) / 2)\n",
    "        term2 = d * (1 - d) / 2 * ((2 - d) / 3 - phi)\n",
    "        eq3 = term1 + term2 - lambdas[2]\n",
    "\n",
    "        return [eq1, eq2, eq3]\n",
    "\n",
    "\n",
    "\n",
    "    initial_guess = [0.1, 0.1, 0.1] \n",
    "    sol = root(equations, initial_guess)\n",
    "\n",
    "    return tuple(sol.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a04d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7830661746919022, 0.1531962604312119, 0.7404699802776804)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompute_lambdas(model.weights.data)\n",
    "\n",
    "#Думаю нужно разобраться с выходами модели - возможно несоответствие по индексам"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
