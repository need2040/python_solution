{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"coursera":{"course_slug":"neural-networks-deep-learning","graded_item_id":"wRuwL","launcher_item_id":"NI888"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eWq8tODVNVwb"},"source":["# Бинарная классификация с применением нейронной сети с одним скрытым слоем\n","\n","В данной лабораторной работе рассмотрим процесс создание нейронной сети с одним скрытым слоем. Сравните данную модель с уже изученной Вами ранее- логистической регрессией.\n","\n","**В результате выполнения данной лабораторной Вы:**\n","- Создадите нейронную сеть с одним скрытым слоем для бинарной классификации\n","- Используете нелинейную функцию активации нейронов, например тангенциальную\n","- Рассчитаете ошибку при помощи перекресной энтропии\n","- Примените алгоритм обратного распространения ошибки\n"]},{"cell_type":"markdown","source":["Создайте файл с именем **planar_utils.py** в корне папки с программой. Вставьте представленный ниже код:"],"metadata":{"id":"qId1nQsgCs_s"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import sklearn\n","import sklearn.datasets\n","import sklearn.linear_model\n","\n","def plot_decision_boundary(model, X, y):\n","    # Set min and max values and give it some padding\n","    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n","    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n","    h = 0.01\n","    # Generate a grid of points with distance h between them\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","    # Predict the function value for the whole grid\n","    Z = model(np.c_[xx.ravel(), yy.ravel()])\n","    Z = Z.reshape(xx.shape)\n","    # Plot the contour and training examples\n","    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n","    plt.ylabel('x2')\n","    plt.xlabel('x1')\n","    plt.scatter(X[0, :], X[1, :], c=y.ravel(), cmap=plt.cm.Spectral)\n","\n","\n","def sigmoid(x):\n","    \"\"\"\n","    Compute the sigmoid of x\n","\n","    Arguments:\n","    x -- A scalar or numpy array of any size.\n","\n","    Return:\n","    s -- sigmoid(x)\n","    \"\"\"\n","    s = 1/(1+np.exp(-x))\n","    return s\n","\n","def load_planar_dataset():\n","    np.random.seed(1)\n","    m = 400 # number of examples\n","    N = int(m/2) # number of points per class\n","    D = 2 # dimensionality\n","    X = np.zeros((m,D)) # data matrix where each row is a single example\n","    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n","    a = 4 # maximum ray of the flower\n","\n","    for j in range(2):\n","        ix = range(N*j,N*(j+1))\n","        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n","        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n","        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n","        Y[ix] = j\n","\n","    X = X.T\n","    Y = Y.T\n","\n","    return X, Y\n","\n","def load_extra_datasets():\n","    N = 200\n","    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n","    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n","    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n","    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n","    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n","\n","    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure"],"metadata":{"id":"qKxWVetSCzwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Создайте файл с именем **testCases.py** в корне папки с программой. Вставьте представленный ниже код:"],"metadata":{"id":"u-URtRaCC3ei"}},{"cell_type":"code","source":["import numpy as np\n","\n","def layer_sizes_test_case():\n","    np.random.seed(1)\n","    X_assess = np.random.randn(5, 3)\n","    Y_assess = np.random.randn(2, 3)\n","    return X_assess, Y_assess\n","\n","def initialize_parameters_test_case():\n","    n_x, n_h, n_y = 2, 4, 1\n","    return n_x, n_h, n_y\n","\n","\n","def forward_propagation_test_case():\n","    np.random.seed(1)\n","    X_assess = np.random.randn(2, 3)\n","    b1 = np.random.randn(4,1)\n","    b2 = np.array([[ -1.3]])\n","\n","    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n","        [-0.02136196,  0.01640271],\n","        [-0.01793436, -0.00841747],\n","        [ 0.00502881, -0.01245288]]),\n","     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n","     'b1': b1,\n","     'b2': b2}\n","\n","    return X_assess, parameters\n","\n","def compute_cost_test_case():\n","    np.random.seed(1)\n","    Y_assess = (np.random.randn(1, 3) > 0)\n","    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n","        [-0.02136196,  0.01640271],\n","        [-0.01793436, -0.00841747],\n","        [ 0.00502881, -0.01245288]]),\n","     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n","     'b1': np.array([[ 0.],\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]]),\n","     'b2': np.array([[ 0.]])}\n","\n","    a2 = (np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]))\n","\n","    return a2, Y_assess, parameters\n","\n","def backward_propagation_test_case():\n","    np.random.seed(1)\n","    X_assess = np.random.randn(2, 3)\n","    Y_assess = (np.random.randn(1, 3) > 0)\n","    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n","        [-0.02136196,  0.01640271],\n","        [-0.01793436, -0.00841747],\n","        [ 0.00502881, -0.01245288]]),\n","     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n","     'b1': np.array([[ 0.],\n","        [ 0.],\n","        [ 0.],\n","        [ 0.]]),\n","     'b2': np.array([[ 0.]])}\n","\n","    cache = {'A1': np.array([[-0.00616578,  0.0020626 ,  0.00349619],\n","         [-0.05225116,  0.02725659, -0.02646251],\n","         [-0.02009721,  0.0036869 ,  0.02883756],\n","         [ 0.02152675, -0.01385234,  0.02599885]]),\n","  'A2': np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]),\n","  'Z1': np.array([[-0.00616586,  0.0020626 ,  0.0034962 ],\n","         [-0.05229879,  0.02726335, -0.02646869],\n","         [-0.02009991,  0.00368692,  0.02884556],\n","         [ 0.02153007, -0.01385322,  0.02600471]]),\n","  'Z2': np.array([[ 0.00092281, -0.00056678,  0.00095853]])}\n","    return parameters, cache, X_assess, Y_assess\n","\n","def update_parameters_test_case():\n","    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n","        [-0.02311792,  0.03137121],\n","        [-0.0169217 , -0.01752545],\n","        [ 0.00935436, -0.05018221]]),\n"," 'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n"," 'b1': np.array([[ -8.97523455e-07],\n","        [  8.15562092e-06],\n","        [  6.04810633e-07],\n","        [ -2.54560700e-06]]),\n"," 'b2': np.array([[  9.14954378e-05]])}\n","\n","    grads = {'dW1': np.array([[ 0.00023322, -0.00205423],\n","        [ 0.00082222, -0.00700776],\n","        [-0.00031831,  0.0028636 ],\n","        [-0.00092857,  0.00809933]]),\n"," 'dW2': np.array([[ -1.75740039e-05,   3.70231337e-03,  -1.25683095e-03,\n","          -2.55715317e-03]]),\n"," 'db1': np.array([[  1.05570087e-07],\n","        [ -3.81814487e-06],\n","        [ -1.90155145e-07],\n","        [  5.46467802e-07]]),\n"," 'db2': np.array([[ -1.08923140e-05]])}\n","    return parameters, grads\n","\n","def nn_model_test_case():\n","    np.random.seed(1)\n","    X_assess = np.random.randn(2, 3)\n","    Y_assess = (np.random.randn(1, 3) > 0)\n","    return X_assess, Y_assess\n","\n","def predict_test_case():\n","    np.random.seed(1)\n","    X_assess = np.random.randn(2, 3)\n","    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n","        [-0.02311792,  0.03137121],\n","        [-0.0169217 , -0.01752545],\n","        [ 0.00935436, -0.05018221]]),\n","     'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n","     'b1': np.array([[ -8.97523455e-07],\n","        [  8.15562092e-06],\n","        [  6.04810633e-07],\n","        [ -2.54560700e-06]]),\n","     'b2': np.array([[  9.14954378e-05]])}\n","    return parameters, X_assess"],"metadata":{"id":"xPW8o6xRC89W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laPHt95uJx_-"},"source":["## 1 - Библиотеки ##\n","\n","Вначале импортируем следующие необходимые для выполнения лабораторной работы библиотеки:\n","- [numpy](https://www.numpy.org/) - одна из основных библиотек для работы с данными при использовании языка Python.\n","- [sklearn](http://scikit-learn.org/stable/) предоставляет простые и эффективные модели для анализа данных\n","- [matplotlib](http://matplotlib.org) - это библиотека для создания графиков.\n","- Модуль testCases содержит набор тестовых примеров и позволяет оценить корректность реализованных Вами функций.\n","- Модуль planar_utils содержит множество функций используемых в данной лабораторной работе."]},{"cell_type":"code","metadata":{"id":"XXqRV1dVJyAD"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from testCases import *\n","import sklearn\n","import sklearn.datasets\n","import sklearn.linear_model\n","from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n","\n","%matplotlib inline\n","\n","np.random.seed(1) # не меняйте это значение для автоматической проверки правильности выполнения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U_KXsVtaJyAR"},"source":["## 2 - Набор данных ##\n","\n","Для начала загрузим данные, которые необходимо анализировать. Следующий код загружает набор данных \"Полярная роза\" (известная математическая кривая, похожая на цветок с лепестками). Загрузим координаты точек `X` и `Y`."]},{"cell_type":"code","metadata":{"id":"TnCck5ilJyAU"},"source":["X, Y = load_planar_dataset()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECBd7x-PJyAf"},"source":["Визуализируем данные с помощью библиотеки matplotlib. Точки представляют собой \"цветок\" и имеют красные маркеры (y=0) и синие (y=1). Необходимо создать модель классификации точек по цвету."]},{"cell_type":"code","metadata":{"id":"j5257eAmJyAi"},"source":["plt.scatter(X[0, :], X[1, :], c=Y.ravel(), s=40, cmap=plt.cm.Spectral)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P88GPbJvJyAs"},"source":[" Имеем:\n","    - numpy-массив (матрица) X содержащая переменные (x1, x2)\n","    - numpy-массив (вектор) Y содержащий метку класса (красный:0, синий:1).\n","\n","\n","**Задание**: Каков размер вашей обучающей выборки? А также,какова форма numpy-массивов `X` и `Y`?\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"f5885023d1a7e5fc53f0534b5945c381","grade":true,"grade_id":"shape","locked":false,"points":1,"schema_version":1,"solution":true},"id":"dqEMZPNikHx-"},"source":["YOUR ANSWER HERE"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"c781a5e316e0f7d62e4aadac5804973d","grade":false,"grade_id":"sh","locked":false,"schema_version":1,"solution":true},"id":"rVQHd1TUkHyC"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()\n","\n","print ('Форма X: ' + str(shape_X))\n","print ('Форма Y: ' + str(shape_Y))\n","print ('m = ',m)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"qwNMCQIkJyAw","nbgrader":{"checksum":"3693f20313b200d7c4886f4f771f7dd0","grade":true,"grade_id":"shape_code","locked":true,"points":0.5,"schema_version":1,"solution":false}},"source":["assert shape_X == (2,400)\n","assert shape_Y == (1,400)\n","assert m == 400"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LGnHoO38JyA-"},"source":["## 3 - Логистическая регрессия\n","\n","Перед созданием нейронной сети рассмотрим применимость логистической регрессии в данном случае. Для этого Вы можете использовать встроенные функции библиотеки sklearn. Запустите следующий код для обучения классификатора на основе логистической регрессии по представленным данным."]},{"cell_type":"code","metadata":{"id":"Z1U2fLFVJyBB"},"source":["clf = sklearn.linear_model.LogisticRegressionCV();\n","clf.fit(X.T, Y.T);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwS14eTbJyBK"},"source":["Теперь вы можете визуализировать границу раздела классов для данной модели. Запустите код? предложенный ниже."]},{"cell_type":"code","metadata":{"id":"JaM2gTfhJyBM"},"source":["plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n","plt.title(\"Логистическая регрессия\")\n","\n","LR_predictions = clf.predict(X.T)\n","print ('Точность логистической регрессии: ', float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100),\n","       '% (процент правильно классифицированных точек)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYT8JqTxJyBY"},"source":["**Задание**: Объясните низкий процент точности при применении логистической регреессии к данной задаче."]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"3ba678d437a1f366a112cf5969c09601","grade":true,"grade_id":"ans1","locked":false,"points":1,"schema_version":1,"solution":true},"id":"hsWHLjLgkHyg"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"vElJNORJkHyh"},"source":["## 4 - Нейронная сеть\n","\n","Алгоритм логистичской регрессии показал слабую классификацию на наборе данных \"Полярная роза\". Далее Вам предстоить использовать нейронную сеть с одним скрытым слоем для улучшения качества класссификации.\n","\n","**Архитектура используемой сети с одним скрытым слоем**:\n","<img src=\"https://drive.google.com/uc?id=1brDmfJ-irjQTnLe_4fzjBXRsNZo9ghzc\" width=70%>\n","\n","**Алгоритм обучения нейронной сети**:\n","\n","Для экземпляра данных $x^{(i)}$:\n","$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}$$\n","$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n","$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}$$\n","$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n","$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{, если } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{, иначе } \\end{cases}\\tag{5}$$\n","\n","Используя все обучающие примеры, в качестве функции ошибки ИНС будем оценивать функционал стоимости $J$ как:\n","$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n","\n","**Важно**: Используем алогоритм построения искусственной нейронной сети:\n","    1. Определить архитектуру нейросетевой модели ( количество входов,  число скрытых слоев, размеры слоев и другие).\n","    2. Инициализировать параметры модели (веса, смещения, граденты, оценку функционала и другие)\n","    3. На каждой итерации обучения:\n","        - Прямое распространение сигнала по сети (предъявление очередного\n","        набора из обучающей выборки на вход нейронной сети)\n","        - Вычисление выходного сигнала сети и функции ошибки\n","        - Обратное распространение ошибки и определение величин ошибок нейронов\n","        - Обновление весов сети (методом градиентного спуска)\n","\n","В начале следует реализовать основные функции алгоритма, а затем использовать их в правильном порядке в главной функции модели `nn_model()`. После реализации `nn_model()` и обучения нейронной сети Вы получите классификатор и сможете его применить на \"новых\" для сети данных (которых не было в обучающем наборе)."]},{"cell_type":"markdown","metadata":{"id":"baYMrmgHkHyi"},"source":["### 4.1 - Определение архитектуры нейронной сети ####\n","\n","**Задание**: Определите три переменных в соотвествии с изображением:\n","    - n_x: размер входного слоя\n","    - n_h: размер скрытого слоя\n","    - n_y: размер выходного слоя"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"21f41a25b845d1335e1b8d2fbbce283f","grade":false,"grade_id":"size","locked":false,"schema_version":1,"solution":true},"id":"TM5CT1tNkHyj"},"source":["def layer_sizes(X, Y):\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","    return (n_x, n_h, n_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5a09fb81dd85afb1b079bde5403a3c85","grade":true,"grade_id":"correct_size","locked":true,"points":1,"schema_version":1,"solution":false},"id":"E0jVPQzpkHyp"},"source":["X_assess, Y_assess = layer_sizes_test_case()\n","(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)\n","print(\"Размер входного слоя: n_x = \" + str(n_x))\n","print(\"Размер скрытого слоя: n_h = \" + str(n_h))\n","print(\"Размер выходного слоя: n_y = \" + str(n_y))\n","\n","assert n_x == 5\n","assert n_h == 4\n","assert n_y == 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JDAt9cnkHys"},"source":["### 4.2 - Инициализация параметров модели ####\n","\n","**Задание**: Реализуйте функцию `initialize_parameters()`, которая инициализирует веса W нейронов вещественными случайными числами и смещения b нулями."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"26367a86a28513179c03fa2d75c88588","grade":false,"grade_id":"init","locked":false,"schema_version":1,"solution":true},"id":"xUjbO84CkHyt"},"source":["def initialize_parameters(n_x, n_h, n_y):\n","    np.random.seed(2) # не меняйте значение для автопроверки\n","\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    assert (W1.shape == (n_h, n_x))\n","    assert (b1.shape == (n_h, 1))\n","    assert (W2.shape == (n_y, n_h))\n","    assert (b2.shape == (n_y, 1))\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","\n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"1dab945850e7642303f54a28ad634fe8","grade":true,"grade_id":"correct_init","locked":false,"points":1,"schema_version":1,"solution":true},"id":"LYci7-oFkHyx"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pXGvF2A5kHy1"},"source":["### 4.3 - Цикл обучения ####\n","\n","**Задание**: Реализуйте функцию прямого распространения сигнала по сети `forward_propagation()`.\n","\n","**Указания**:\n","- Следуйте математическому описанию работы нейрона.\n","- Используйте функцию `sigmoid()` из пакета planar_utils и тангенциальную функцию np.tanh().\n","- Реализуйте прямое распространение обучающей выборки по сети, вычислив векторы выходных значений и активаций нейронов $Z^{[1]}, A^{[1]}, Z^{[2]}$ и $A^{[2]}$.\n","- Значения для вышисления ошибок при обратном распространении ошибок сохраняются в \"`cache`\"."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"65ebc6f3267dcbc440d20d3d558d2952","grade":false,"grade_id":"fp","locked":false,"schema_version":1,"solution":true},"id":"ZNmfLwZ7kHy4"},"source":["def forward_propagation(X, parameters):\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    cache = {\"Z1\": Z1,\n","             \"A1\": A1,\n","             \"Z2\": Z2,\n","             \"A2\": A2}\n","\n","    return A2, cache"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"3d38eea7686c84c633f51e5220347ee2","grade":true,"grade_id":"correct_fp","locked":true,"points":1,"schema_version":1,"solution":false},"id":"XME4Ojl5kHy9"},"source":["X_assess, parameters = forward_propagation_test_case()\n","A2, cache = forward_propagation(X_assess, parameters)\n","\n","print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))\n","\n","assert(A2.shape == (1, X_assess.shape[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEai5YsikHzB"},"source":["После вычисления вектора $A^{[2]}$ выходных значений нейрона выходного слоя для каждого экземпляра обучающей выборки $a^{[2](i)}$, необходимо вычислить функционал стоимости (ошибки) на основе перекрестной энтропии:\n","\n","$$J = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n","\n","**Задание**: Реализуйте функцию `compute_cost()` для расчета функционала ошибки $J$ с помощью."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"74b7caee3498a11a019ca0cbe01092f4","grade":false,"grade_id":"cost","locked":false,"schema_version":1,"solution":true},"id":"Wiu0neKykHzD"},"source":["def compute_cost(A2, Y, parameters):\n","    m = Y.shape[1]\n","\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    return cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f3eaccd1b4ed49fe1cc2ac2aef6e43cc","grade":true,"grade_id":"correct_cost","locked":true,"points":1,"schema_version":1,"solution":false},"id":"fBnaZvy8kHzH"},"source":["A2, Y_assess, parameters = compute_cost_test_case()\n","\n","cost = compute_cost(A2, Y_assess, parameters)\n","print(\"cost = \" + str(cost))\n","\n","assert(isinstance(cost, float))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjQ3EcsMkHzL"},"source":["**Задание**: Используя сохраненные значения при прямом проходе, реализуйте обратное распространение ошибки `backward_propagation()`.\n","\n","**Указания**:\n","Минимизация методом градиентного спуска обеспечивает подстройку весовых коэффициентов следующим образом:  \n","\n","<img src=\"https://drive.google.com/uc?id=1KH_eI13-RlGOvp0OPyRGom4tlxCxHWof\" width=80%>\n","\n","<!--\n","$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n","\n","$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n","\n","$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n","\n","$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n","\n","$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n","\n","$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n","\n","- Note that $*$ denotes elementwise multiplication.\n","- The notation you will use is common in deep learning coding:\n","    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n","    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n","    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n","    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n","    \n","!-->\n","\n","- Совет:\n","    - Для вычисления dZ1 необходимо вычислить $g^{[1]'}(Z^{[1]})$. Т.к. $g^{[1]}(.)$ - тангенциальная функция активации, если $a = g^{[1]}(z)$, то $g^{[1]'}(z) = 1-a^2$. Так вы можете вычислить\n","    $g^{[1]'}(Z^{[1]})$ используя `(1 - np.power(A1, 2))`."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"b32a856c3b9f05e1d90a61eafe319c98","grade":false,"grade_id":"bp","locked":false,"schema_version":1,"solution":true},"id":"Vy4Vp0YZkHzN"},"source":["def backward_propagation(parameters, cache, X, Y):\n","    m = X.shape[1]\n","\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    grads = {\"dW1\": dW1,\n","             \"db1\": db1,\n","             \"dW2\": dW2,\n","             \"db2\": db2}\n","\n","    return grads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"f6bb34af58b4fd6f318492eee86f21f6","grade":true,"grade_id":"correct_bp","locked":false,"points":2,"schema_version":1,"solution":true},"id":"dZunnbUBkHzS"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8K3OWLQkHzW"},"source":["**Проверочные значения**:\n","\n","\n","\n","<table style=\"width:80%\">\n","  <tr>\n","    <td>**dW1**</td>\n","    <td> [[ 0.00301023 -0.00747267]\n"," [ 0.00257968 -0.00641288]\n"," [-0.00156892  0.003893  ]\n"," [-0.00652037  0.01618243]] </td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**db1**</td>\n","    <td>  [[ 0.00176201]\n"," [ 0.00150995]\n"," [-0.00091736]\n"," [-0.00381422]] </td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**dW2**</td>\n","    <td> [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] </td>\n","  </tr>\n","  \n","\n","  <tr>\n","    <td>**db2**</td>\n","    <td> [[-0.16655712]] </td>\n","  </tr>\n","  \n","</table>  "]},{"cell_type":"markdown","metadata":{"id":"rtfJnBiDkHzX"},"source":["**Задание**: Реализуйте коррекцию весов, используя (dW1, db1, dW2, db2) для обновления (W1, b1, W2, b2).\n","\n","**Правило обновления весов градиентного спуска**: $ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$, где $\\alpha$ - это параметр скорости обучения, а $\\theta$ представляет обновляемый параметр.\n","\n","Алгоритм градиентного спуска с оптимальной скорость обучения сходится, а с плохо подобранной - расходится.\n","\n","<img src=\"https://drive.google.com/uc?id=17C5-UNXd2Ec2aYKU_DtosW_WkDXwyGGk\" style=\"width:400;height:400;\"> <img src=\"https://drive.google.com/uc?id=1ePjQsFSElPrwIZtaqFVvquvm-d7Q2_2a\" style=\"width:400;height:400;\">\n","\n"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"209ba098f811965f756167626eeffe51","grade":false,"grade_id":"up","locked":false,"schema_version":1,"solution":true},"id":"OTudImyGkHzZ"},"source":["def update_parameters(parameters, grads, learning_rate = 1.2):\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","\n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"38217e5312e005d3af7068cce00ad9b4","grade":true,"grade_id":"correct_up","locked":false,"points":1,"schema_version":1,"solution":true},"id":"IPCh524CkHzd"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-aVFYDikHzk"},"source":["**Ожидаемые значения**:\n","\n","\n","<table style=\"width:80%\">\n","  <tr>\n","    <td>**W1**</td>\n","    <td> [[-0.00643025  0.01936718]\n"," [-0.02410458  0.03978052]\n"," [-0.01653973 -0.02096177]\n"," [ 0.01046864 -0.05990141]]</td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**b1**</td>\n","    <td> [[ -1.02420756e-06]\n"," [  1.27373948e-05]\n"," [  8.32996807e-07]\n"," [ -3.20136836e-06]]</td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**W2**</td>\n","    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td>\n","  </tr>\n","  \n","\n","  <tr>\n","    <td>**b2**</td>\n","    <td> [[ 0.00010457]] </td>\n","  </tr>\n","  \n","</table>  "]},{"cell_type":"markdown","metadata":{"id":"5mjnZ0OjkHzo"},"source":["### 4.4 - Построение модели нейронной сети nn_model() ####\n","\n","**Задание**: Постройте нейросетевую модель в функции `nn_model()`, используя реализованные функции."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"b484bef0c23fe882ddb069b377a05d6c","grade":false,"grade_id":"Model","locked":false,"schema_version":1,"solution":true},"id":"vMxB1LJxkHzq"},"source":["def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n","\n","    np.random.seed(3)\n","    n_x = layer_sizes(X, Y)[0]\n","    n_y = layer_sizes(X, Y)[2]\n","\n","    # parameters =\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    # Loop (gradient descent)\n","\n","    for i in range(0, num_iterations):\n","\n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","\n","        # Print the cost every 1000 iterations\n","        if print_cost and i % 1000 == 0:\n","            print (\"Значение ошибки после %i итерации: %f\" %(i, cost))\n","\n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"b303e6b510d1f1b27ca2f3783f62d87a","grade":true,"grade_id":"correct_model","locked":false,"points":3,"schema_version":1,"solution":true},"id":"r9M-tIsTkHzu"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eSxE17OQkHzx"},"source":["**Ожидаемые значения**:\n","\n","<table style=\"width:90%\">\n","\n","<tr>\n","    <td>\n","        **cost after iteration 0**\n","    </td>\n","    <td>\n","        0.692739\n","    </td>\n","</tr>\n","\n","<tr>\n","    <td>\n","        <center> $\\vdots$ </center>\n","    </td>\n","    <td>\n","        <center> $\\vdots$ </center>\n","    </td>\n","</tr>\n","\n","  <tr>\n","    <td>**W1**</td>\n","    <td> [[-0.65848169  1.21866811]\n"," [-0.76204273  1.39377573]\n"," [ 0.5792005  -1.10397703]\n"," [ 0.76773391 -1.41477129]]</td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**b1**</td>\n","    <td> [[ 0.287592  ]\n"," [ 0.3511264 ]\n"," [-0.2431246 ]\n"," [-0.35772805]] </td>\n","  </tr>\n","  \n","  <tr>\n","    <td>**W2**</td>\n","    <td> [[-2.45566237 -3.27042274  2.00784958  3.36773273]] </td>\n","  </tr>\n","  \n","\n","  <tr>\n","    <td>**b2**</td>\n","    <td> [[ 0.20459656]] </td>\n","  </tr>\n","  \n","</table>  "]},{"cell_type":"markdown","metadata":{"id":"RfUoz4iiJyDt"},"source":["### 4.5 Прогноз\n","\n","**Задание**: Реализуйте функцию predict() для прогноза модели.\n","Используйте прямое распространение сигнала по сети.\n"]},{"cell_type":"code","metadata":{"deletable":false,"id":"iVStG907JyDx","nbgrader":{"checksum":"18cb2756f5a9d0d2e188293d64359bae","grade":false,"grade_id":"pr","locked":false,"schema_version":1,"solution":true}},"source":["def predict(parameters, X):\n","    \"\"\"\n","    Используя параметры обученной модели, предскажем класс для каждого примера в X\n","\n","    Аргументы:\n","    parameters -- Словарь python хранит в себе параметры вашей модели\n","    X -- входные данные размерности (n_x, m)\n","\n","    Выход функции\n","    predictions -- Вектор с прогнозом вашей модели (красный: 0 / синий: 1)\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","    raise NotImplementedError()\n","\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"id":"X9A-J9J1JyD5","nbgrader":{"checksum":"e672687e05979d8c2ea7c3a62181d7fa","grade":true,"grade_id":"correct_pr","locked":true,"points":0,"schema_version":1,"solution":false}},"source":["parameters, X_assess = predict_test_case()\n","\n","predictions = predict(parameters, X_assess)\n","print(\"predictions mean = \" + str(np.mean(predictions)))\n","\n","assert round(np.mean(predictions),3)==0.667"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hq0gGbVaJyEF"},"source":["Давайте запустим модель и посмотрим как она справится со всем набором данных. Запустите следующий код и протестируйте свою нейронную сеть с одим скрытым слоем, содержащим $n_h$ нейронов."]},{"cell_type":"code","metadata":{"id":"cWpqHLywJyEH"},"source":["parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n","\n","plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n","plt.title(\"Decision Boundary for hidden layer size \" + str(4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FzYjJhg_JyEV"},"source":["**Ожидаемый выход**:\n","\n","<table style=\"width:40%\">\n","  <tr>\n","    <td>**Cost after iteration 9000**</td>\n","    <td> 0.218607 </td>\n","  </tr>\n","  \n","</table>\n"]},{"cell_type":"code","metadata":{"id":"JLmLN-_XJyEX"},"source":["predictions = predict(parameters, X)\n","print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxZIfllNJyEh"},"source":["**Expected Output**:\n","\n","<table style=\"width:15%\">\n","  <tr>\n","    <td>**Accuracy**</td>\n","    <td> 90% </td>\n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"96c_KwG3JyEj"},"source":["Точность значительно увеличилась по сравнению с логистической регрессией, давайте теперь попробуем различные варианты реализации скрытого слоя."]},{"cell_type":"markdown","metadata":{"id":"Fd6yWDT9JyEk"},"source":["### 4.6 - Изменение количество нейронов на скрытом слое ###\n","\n","Запустите следующий код. Проанализируйте влияние размерности скрытого слоя на результат классификации."]},{"cell_type":"code","metadata":{"id":"SAu6_5mqJyEn"},"source":["plt.figure(figsize=(16, 32))\n","hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n","for i, n_h in enumerate(hidden_layer_sizes):\n","    plt.subplot(5, 2, i+1)\n","    plt.title('Размер скрытого слоя %d' % n_h)\n","    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n","    plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n","    predictions = predict(parameters, X)\n","    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n","    print (\"Точность для {} скрытого слоя: {} %\".format(n_h, accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fxZDDCDoJyEu"},"source":["**Объяснения**:\n","- Чем больше нейронов на скрытом слое, тем более точно модель описывает обучающую выборку, пока в какой-то момент максимально большая модель не переучится.\n","- Наиболее удачной будет модель с 5-ю нейронами на скрытом слое. При этом значении переобучение еще не происходит.\n","- Позже вы познакомитесь с понятием \"регуляризация\". Регуляризация позволяет использовать модели с большим количеством нейронов на скрытом слое без переобучения сети."]},{"cell_type":"markdown","metadata":{"id":"CHT7UGlxJyEx"},"source":["**Вопросы**:\n","\n","- Что произойдет если изменить функцию активации с tanh на sigmoid или на ReLU?\n","- Проанализируйте на что влияет изменение learning_rate.\n","- Выберите датасет из раздела 5, согласно своему варианту."]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"b302824520b5223ce499dd18e4e547f7","grade":true,"grade_id":"train1","locked":false,"points":2.5,"schema_version":1,"solution":true},"id":"ZOx3JPTMkH0P"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"998DBgHLJyFJ"},"source":["## 5) Самостоятельная работа.\n","Выберите датасет согласно своему варианту. Обучите нейронную сеть и выполните классификацию. Постройте график ошибки на обучении, подберите наилучшую скорость обучения и количество эпох обучения. Сделайте выводы. Испробуте другие варианты архитектуры и функций активации на платформе http://playground.tensorflow.org/"]},{"cell_type":"code","metadata":{"deletable":false,"id":"RDRZhBZyJyFO","nbgrader":{"checksum":"956dae3abf1a25c9e0ad1f5ada1e62be","grade":true,"grade_id":"train","locked":false,"points":4,"schema_version":1,"solution":true}},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"checksum":"aab8710a39383989b1825fcf8f224908","grade":true,"grade_id":"concl","locked":false,"points":1,"schema_version":1,"solution":true},"id":"bU4NAVLSkH0U"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"Okf99MbXJR01"},"source":["Контрольные вопросы:\n","1. Что входит в понятие архитектуры нейронной сети?\n","2. Какие параметры есть у нейронных сетей и как они могут быть инициализированы?\n","3. Что такое функционал стоимости? Для чего он нужен?\n"]}]}