{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45013cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Наметки архитектуры\n",
    "1. Генератор QPSK сигналов (Подтянуть теорию в вопросе модуляции)\n",
    "1.1. Требуемые параметры - частота дискретизации, несущая частота, длительность сигнала (сек)\n",
    "1.2. Гибкость в наложении шумов - имеет смысл сделать версию с простыми аугментациями, после уже пытаться генерировать что-то более неадекватное\n",
    "2. Контрастивное обучение (вообще нужно, и если да, то на каком этапе?) (в первой статье: https://arxiv.org/abs/2304.03588 используется только на pre-train и fine-tuning, backbone по типу UNet)\n",
    "2.1. Сама архитектура будет энкодер-декодер - не вижу смысл делать трансформер (поскольку сами последовательности короткие, а проблема затухающих градиентов вряд ли проявится, если использовать батчнорму и пр.)\n",
    "2.2. Не трансформер = использовать только свертки, пулинги и проекции, без attention механизмов (возможно зря, нужны тесты)\n",
    "2.3. Нужно прикинуть несколько возможных вариантов и переработать, дальше уже обдумывать датасет и пр.\n",
    "\n",
    "Главный вопрос - как ставить задачу - если по первой статье, то будем кластеризовывать шумы (но только не претрейнинге, дальше тупо Unet) - это и есть SIMClr. Потенциально полезная история - кластеризовать различные виды шумов уже из более реальных семплов,\n",
    "соответственно разметить данные по аугментациям, а дальше думать над основной архитектурой - при чём будет решаться задача классификации на предобработанных кластерах, есть вопросы по их количеству и тому, что будем называть разными кластерами, но думаю это само решиться если взять \n",
    "огромный датасет)\n",
    "\n",
    "Вопрос в backbone\n",
    "\n",
    "По-факту нужны в любом случае ground-truth, однако они могут быть получены с помощью SIMCLR (см. выше), то есть я смогу подавать различные виды шумов, там будет использоваться patch-wise contrasting learning (Sn - различные шумы, n - число кластеров) \n",
    "(есть проблема с ground truth чистыми данными, однако они как раз таки могут выявиться на этапе кластеризации или потенциально их можно сгенерировать синтетикой))\n",
    "\n",
    "Для того, что бы организовать процесс NASS нужны именно ground truth шумов, а не чистых сигналов, а их то мы как раз найдем с помощью SIMCLR (см.Ниже)\n",
    "\n",
    "Данные: \n",
    "Вижу два основных варианта - генерировать QPSK или LibriMix\n",
    "\n",
    "Плюсы генерации руками - интерпретируемость, возсможность генерировать максимально приближенные к реальным данные (именно QPSK модулированные, а не какие то случайные гармоники)\n",
    "Минусы - сложно будет сгенерировать шумы, приближенные к реальным\n",
    "\n",
    "LibriMix - \n",
    "Плюс - Огромный датасет, с различными аугментациями (400 GB), выбор частоты дискретизации\n",
    "Минус - все- таки это не QPSK сигнал, а речь, соответственно может быть не применимо в моей задаче.\n",
    "\n",
    "Думаю для проверки корректности работы на простых шумах правильно будет использовать QPSK модуляцию\n",
    "\n",
    "Датасет: \n",
    "\n",
    "Очевидно, для предваррительной кластеризации ои обучения будут исползьвоаться два разных датасета \n",
    "\n",
    "Promising papers:\n",
    "https://arxiv.org/html/2305.10761v3\n",
    "https://arxiv.org/abs/2304.03588\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b055a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
