{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, inputs, targets, criterion, weights = None, compute_grad=False):\n",
    "    '''\n",
    "    Computes gradients of model with given inputs and targets and loss function.\n",
    "    Optionally backpropagates to compute gradients for weights.\n",
    "    Procedure depends on whether we have one model for each source or not\n",
    "    :param model: Model to train with\n",
    "    :param inputs: Input mixture\n",
    "    :param targets: Target sources\n",
    "    :param criterion: Loss function to use (L1, L2, ..) это имеется ввиду Loss1, Loss2 или L1-norm, L2-norm? \n",
    "    :param compute_grad: Whether to compute gradients\n",
    "    :return: Model outputs, Average loss over batch\n",
    "\n",
    "    я так понимаю, что возвращается\n",
    "    '''\n",
    "    all_outputs = {}\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [1.0] * len(criterion)\n",
    "\n",
    "    loss_values = np.zeros_like(criterion)\n",
    "\n",
    "    if model.separate:\n",
    "        avg_loss = 0.0\n",
    "        num_sources = 0\n",
    "        for inst in model.instruments:\n",
    "            output = model(inputs, inst)\n",
    "            loss = criterion(output[inst], targets[inst])\n",
    "\n",
    "            if compute_grad:\n",
    "                loss.backward()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "            num_sources += 1\n",
    "\n",
    "            all_outputs[inst] = output[inst].detach().clone()\n",
    "\n",
    "        avg_loss /= float(num_sources)\n",
    "    else:\n",
    "        loss = 0\n",
    "        all_outputs = model(inputs)\n",
    "        for inst in all_outputs.keys():\n",
    "            loss += criterion(all_outputs[inst], targets[inst])\n",
    "\n",
    "        if compute_grad:\n",
    "            loss.backward()\n",
    "\n",
    "        avg_loss = loss.item() / float(len(all_outputs))\n",
    "\n",
    "    return all_outputs, avg_loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
